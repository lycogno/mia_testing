{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6lrKwKTorKdc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2AeHp_PrKde",
        "outputId": "721c8260-ec30-4ebb-ad8d-74098e263a85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the images to range [-1, 1]\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kHxt7xUFrKdf"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QrXJ6qNrKdg",
        "outputId": "cdd44bfb-9ab1-4a15-c42a-29d4d9e74504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "resnet_model = models.resnet18(pretrained=False)\n",
        "resnet_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet_model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetModel(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.resnet = resnet_model\n",
        "    self.dense_head = nn.Sequential(\n",
        "        nn.Linear(1000, 10),\n",
        "        nn.Softmax(),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = self.resnet(x)\n",
        "    x = self.dense_head(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "2FQGEYP00HGv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnetmodel = ResNetModel().to(device)"
      ],
      "metadata": {
        "id": "UJ5zkdNn1c1N"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T79ji9c4rKdh",
        "outputId": "ffe2ef28-d5d1-4f4e-b5c2-3c89e60a96a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1, Batch 200] Loss: 2.286\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 1, Batch 400] Loss: 2.229\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 1, Batch 600] Loss: 2.175\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 2, Batch 200] Loss: 2.092\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 2, Batch 400] Loss: 2.054\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 2, Batch 600] Loss: 2.043\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 3, Batch 200] Loss: 1.999\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 3, Batch 400] Loss: 1.983\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 3, Batch 600] Loss: 1.973\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 4, Batch 200] Loss: 1.934\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 4, Batch 400] Loss: 1.932\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 4, Batch 600] Loss: 1.926\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 5, Batch 200] Loss: 1.892\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 5, Batch 400] Loss: 1.889\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 5, Batch 600] Loss: 1.884\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 6, Batch 200] Loss: 1.851\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 6, Batch 400] Loss: 1.852\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 6, Batch 600] Loss: 1.857\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 7, Batch 200] Loss: 1.824\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 7, Batch 400] Loss: 1.831\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 7, Batch 600] Loss: 1.829\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 8, Batch 200] Loss: 1.797\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 8, Batch 400] Loss: 1.801\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 8, Batch 600] Loss: 1.800\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n",
            "[Epoch 9, Batch 200] Loss: 1.780\n",
            "Output dimensions: torch.Size([64, 10])\n",
            "Label dimensions: torch.Size([64, 10])\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), F.one_hot(data[1].to(device), num_classes=10)\n",
        "        labels = labels.type(torch.FloatTensor).to(device)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = resnetmodel(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 200 == 199:    # Print every 200 mini-batches\n",
        "            print(f\"[Epoch {epoch + 1}, Batch {i + 1}] Loss: {running_loss / 200:.3f}\")\n",
        "            running_loss = 0.0\n",
        "            print(f\"Output dimensions: {outputs.size()}\\nLabel dimensions: {labels.size()}\")\n",
        "\n",
        "print(\"Finished Training ResNet18 on CIFAR-10\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "51U0z9-JsF6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for i, data in enumerate(testloader, 0):\n",
        "        inputs, labels = data[0].to(device), F.one_hot(data[1].to(device))\n",
        "        outputs = resnetmodel(inputs)\n",
        "        if(i==0):\n",
        "          print(f\"Output dimensions: {outputs.size()}\\nLabel dimensions: {labels.size()}\")\n",
        "        outputs = torch.argmax(outputs, dim=1)\n",
        "        labels = torch.argmax(labels, dim=1)\n",
        "        correct += torch.sum(torch.eq(outputs, labels))\n",
        "        total += 64\n",
        "print(f\"Test accuracy: {correct/total*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "3j2tfr1SsfKY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}